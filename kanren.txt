=============================================================================
1. "Unrolling the Shutter: CNN to Correct Motion Distortions”, in CVPR Oral, 2017.
--challenge[141]
ローリングシャッター現象の改善, 行方向のズレを学習して改善
	
--電車に乗っている時に写真を撮影すると歪んで写ってしまう現象の改善方法.
  既存の手法は複数枚の写真を使用, シーン固有の補正をかけている.

  そこで, 本論文は行方向の歪みをCNNの特徴抽出から算出して補正する手法を提案.
  
  データは256*256のチェスボードの画像と郊外と顔の写真を使用.
  具体的に何%の向上という比較ではなく, 比較手法を2つ再現して, 同じ環境下で3つの
  手法を使用した修正で何ピクセル, n°, PSNR(SNRの改良版っぽい,単位はDb, 数値が大きいほど雑音
  レベルが少なく, 画質良好を意味する.) の3つの尺度を使用して比較している.
  全てでは無いが, 提案手法がほぼ他の2つの手法よりも優れている.(値は微量だが)
  
  カメラのパラメータの事前知識なしに歪みを補正できるのが新規性の部分
  ー>画像のみからk前らの動きと行,列の歪みを検出して補正できる
  ー>他の研究は画像以外からも(例えばカメラとかから)特徴を
     入手しているのに対して,その特徴をなくしても同じ結果を出せるだけでも十分魅力的

=============================================================================
2. "Universal adversarial perturbations”, in CVPR, 2017. (oral) 
--challenge[5]
deep Xplorer に似ている
騙しやすいネットワークを構築

--最先端のディープニューラルネットワーク分類器を考えると、自然画像が高い確率で
  誤分類される原因となる普遍的な（画像に依存しない）摂動ベクトルと非常に
  小さな摂動ベクトル(pertirbation)が存在している。(摂動はかき乱す動き)

  本研究では最先端の深いニューラルネットワークは人間の目にはほとんど知覚できないが、
  誤分類の原因となる摂動に対して非常に脆弱であることを示す。
  我々は、これらの普遍的な摂動をさらに経験的に分析し、
  特に、それらがニューラルネットワーク全体で非常によく一般化することを示した。
  
  背景や物体の見え方による多少のノイズから誤推定してしまう問題の緩和.
  いかにしてネットワークを効率よく騙すか, いかにして効率よく騙されにくい
  ネットワークを構築するかについても議論(DXに繋がる部分)
  
  摂動ベクトル(Perturbation Vector)というもの設定し入力に
  摂動ベクトルを足してそれを新たな入力データとして扱う.
  そのベクトルの値を変化させてネットワークが騙されるか騙されないかの境界線を
  探索していく.

  NNのノイズと誤推定の原因の一つである摂動(Perturbation)に対しての解析は初.
  6つのネットワークをそれぞれ交差して摂動ベクトルを算出して適用させる実験を
  行うことで, ｢騙しやすい入力パターン｣の学習に挑戦している.


=============================================================================
3. "FC4: Fully Convolutional Color Constancy with Confidence-weighted Pooling”, in CVPR, 2017. 
--challenge[8]
画像中の照明色を推定して証明による変化をなくす

--画像中の各パッチに対して正しい色の推定を行って,それらを結合していた.
  しかし, パッチによっては曖昧なものが存在していた.
  (例えば. 白い壁に黄色の照明が当たって黄色っぽく見えるのか, 
   それとももともと黄色っぽい色をした壁なのか など)
  このような曖昧性の含んだパッチ(データ)は学習時においても推定時においても
  結果に対して悪影響を及ぼす.

  この論文では, 入力画像全体を1つのパッチとして扱って,
  Fully Convolutional Networkベース(?)で同時に処理する手法を導入.
  また, 照明の色の推定に対して有用であると思われる領域を推定してPoolingする
  Weighted Poolingを導入. より照明の色に対して頑強な推定手法を実現した.

  Weighted Poolingというデータ内の有用な箇所のみを学習するLayerが新規性.

=============================================================================
4. “Deep Image Matting”, in CVPR, 2017. (oral) 
--challenge[21]
DNNを用いた背景除去の性能アップ
重み付けを調整することで背景を除去する

--静止画の背景除去(Image Matting)において, 前景と背景が似ている場合に
  背景除去が困難であるという問題に取り組んだ論文.

  2段階で学習することでより正確に背景のみを除去することに成功している
  現状(発表時点)では,他のどの手法よりも精度が良い.
  結構アルゴリズムは難しそう.
  Trimapという手法を使用 ー>前景,背景,Unknownの3種に分類する手法


============================================================================
5. “Making Deep Neural Networks Robust to Label Noise: a LossCorrection Approach”, in CVPR, 2017.
--challenge[72]
ラベル付けにノイズが乗っていた時でも正確に学習する
(ノイズに対してロバストなネットワークの構築)

--データセットが増加(これは近年当然のこと)するにつれてどうしても
  CC, 汚染されたデータが含まれる可能性を否定出来なくなってしまっている.
  (間違ったラベル付けが行われたデータがある可能性を考慮しなければならない)

  従来ではノイズに頑強なloss(corrected loss)を計算する手法で対処していたが,
  それはノイズ発生率が既知であるという条件下のもとで性能の評価が行われていた.
  つまり, 実際のデータ(いつ汚染データが含まれるか, どの割合で含まれるかは未知)
  に対しては有用性が証明されていなかった,

  
  

============================================================================
6. “Learning Video Object Segmentation from Static Images”, in CVPR Spotlight, 2017. 
--challenge[92] 難
  動画内のの物体の注目領域マスクを追跡
  オフライン学習とオンライン学習の２つを融合させることで効率の良い動画内での
  動物体の追跡を行う。

  オフライン学習で以前のフレームでの推定により、リファインドなマスクを設定。

  オンライン学習で追跡領域の画像を学習データとしてファインチューニングを逐次的に
  実行することでより精度の高い移動物体の追跡を行う。
  ラベリングのネットワークにはDeepLab v2 -VGGを使用している。


  



################
##--- 2016 ---##
################
=============================================================================
7. “Optical  Flow with  Semantic  Segmentation and  Localized  Layers”, in CVPR ,2016.
--challenge [10]
ある程度領域分割しておいた画像に対してのOpticalFlowを
実行することで移動物体の認識率向上

セマンティックセグメンテーションという画像、動画内においてピクセルごとにどのクラスに属しているかを
ラベリングする技術とオプティカルフローを融合させる手法についての検証。
現在のオプティカルフローでは荒い領域抽出しかできないという問題の解消に取り組む。

密なオプティカルフローや予めセグメント化（クラスタリング）された領域を
事前情報として扱うことで高精度にできる。

とは言ってもまだまだ精度は低い。
データ・セットはKITI-2015というデータ・セットを使用。



============================================================================
8. "Adaptive  Object  Detection  Using  Adjacency and Zoom  Prediction”, CVPR, 2016
--challenge[23]
Faster R-CNNは物体認識の領域を検索する際に2400回ものボックスを検索することで
候補領域を指定することでその候補領域の抽出を適応的にした

Faster R-CNNは2400ものボックス探索をすることで画像内の探索をしている。
領域を区切って適応的な探索を行うことで領域抽出の効率を向上させる。

画像内を５つに分割して隣接領域の移動やズームを適応的に行う。その後にR-CNNの流れ。
物体検出の精度は70.4%、候補領域の抽出においてもFaster R-CNNよりも高い精度を実現。
向上した量は数％上って程度、でも作業量が減って更に精度も高くなるって良いこと

個人的には５分割するよりかは、一度エッジ検出してクラスタリングしてから重みを設定して
NNに突っ込んであげるのもありかなと思う。
５分割して当たりを探しているのは適応的の具合が薄い気もする。
本当に適応的にするのであれば、完全にボックスの当たりを画像ごとに設定できるように
なったほうが良いと思う。
適応的な物体検出に対してはまだまだ可能性があるということは示された。




=============================================================================
9. “Real time Action Recognition with  Enhanced Motion  Vector CNNs”, in CVPR, 2016
--challenge[67]難
オプティカルフローの高速化, 精度をほんの少し犠牲にしているが,
FPSを飛躍的に向上させている.



	 
==============================================================================
10. "Robust Kernel Estimation with Outliers Handling for Image Deblurring", in CVPR, 2016
カメラ撮影時に発生するブレの修正(補正)難
𝐿 [𝑎1*𝑓1 (𝑥) + 𝑎2*𝑓2 (𝑥)] = 𝑎1*𝑔1 𝑥 + 𝑎2*𝑔2
上記の式で変換できるものを線形画像と呼ぶ。 線形関数に代入して変形できる状態のイメージ。
今までのブレ（ぼかし）を特定する研究はこの範囲内でしかブレが起きないという仮定の基で行われていた。

しかし、実際には飽和ピクセルや非ガウスノイズなどの激しい異常値が存在する場合はこの仮定が成り立たないので、
これまでの研究は実用化の面ではまだ残課題があった。

これまでの研究で有名なブラインドデブラーリングアルゴリズムはある範囲でのアウトライア(外れ値)を
処理することはできるが、アウトライアを伴うブレ画像からブレカーネルを
正確に推定するアルゴリズムというのは存在しない.

本研究では信頼性の高い輪郭を利用して中間潜像(肉眼では見えないor見えにくい画像)の
アウトライア(外れ値)を除去する.

＠これも、例えば輪郭がうまく取得できていないことだけに注目すれば、輪郭を抽出して何ピクセルよりも
輪郭が太かったらこれを何分割かしてその中でどれが一番正しいかを考えるという問題で
解決できそうな気もする。


============================================================================
11. "A Comparative Study for Single Image Blind Deblurring", in CVPR, 2016

ブレ補正の論文は基本的に正常な画像を持ってきてそれにブレ処理を
かけて人工的に生成しているが, それを実際に撮影した際にぶれた画像を
使用することで本当に今までの提案手法が有用であるかを検証してる。

多数の単一画像ブラインドブレ除去アルゴリズムが提案されているが、主に合成データセット（人工的に作成したデータセットのこと）か実際のぼけた画像を
使用していたとしても、少量の限られたものしか使用していない。

つまり、実際に生のボケた画像に対してどのような効果を発揮するかは未知数である。
本研究は実際の画像に対しての評価を行った研究となる。

手法としては実際にボケた画像と、合成（人工的に）ぼけた画像の２つを用意する。
これらのデータセットに対してユーザー調査を行い、いくつかの有名な単一ブラインドブレ除去アルゴリズムの性能を評価して性能を定量化していくというもの。

2016年時点での有名なボケ修正アルゴリズムを知れる論文っぽい


============================================================================

=============================================================================

12. A Learning Approach with Under -and Over-sampling for imbalanced Data Sets in IIAI 2016 

高精度に物体を識別するために不均衡なデータセットを是正する。
より良く、より正しいデータセットを見抜くための研究。

手法としては大量に用意出来ているクラスのデータを意図的に減少させて
少量しか用意出来ていないクラスの割合を増やすことで偏りを和らげる。

データを減少させるためにbox-and-whisker plot法というものを使用。
データを増加させるには合成したサンプル（つまり人工的に作成したデータ）を
加えることで行う。

偏りのあるデータセットを物体認識に適したデータセットへ修正していく。



